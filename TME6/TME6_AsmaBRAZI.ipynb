{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arftools import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import copy \n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import random\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import load_digits\n",
    "import tools as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(datax,datay,w):\n",
    "    \"\"\" retourne la moyenne de l'erreur aux moindres carres \"\"\"\n",
    "    return np.mean((np.dot(datax, w.T) - datay)**2)\n",
    "\n",
    "def mse_g(datax,datay,w):\n",
    "    \"\"\" retourne le gradient moyen de l'erreur au moindres carres \"\"\"\n",
    "    return np.mean(2 * (np.dot(datax, w.T) - datay))\n",
    "\n",
    "def hinge(datax,datay,w):\n",
    "    \"\"\" retourn la moyenne de l'erreur hinge \"\"\"\n",
    "    return max(0,-datay * w.dot(datax))\n",
    "\n",
    "def hinge_g(datax,datay,w):\n",
    "    \"\"\" retourne le gradient moyen de l'erreur hinge \"\"\"\n",
    "    if np.mean(datay * np.dot(datax,w.T))<=0:\n",
    "        return np.mean(-datay*datax)\n",
    "    else:\n",
    "        return np.zeros(w.shape)\n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    result=[]\n",
    "    for i in range(0, len(l), n):\n",
    "        result.append(l[i:i+n])\n",
    "    return result\n",
    "\n",
    "def add_bias(datax):\n",
    "    new_dim = np.ones(datax.shape[0]).reshape(-1, 1)\n",
    "    new_datax=np.hstack((datax, new_dim))\n",
    "    return new_datax\n",
    "\n",
    "#calculate the gaussian proj for an example x - miniX \n",
    "def gauss(x,datax, sigma):\n",
    "    x_xdata=x - datax\n",
    "    result=np.zeros((1,x_xdata.shape[0]))\n",
    "    i=0\n",
    "    for norm_s in x_xdata:\n",
    "        result[0][i]=np.exp(-np.linalg.norm(norm_s, 2)**2 / (2. * sigma**2))\n",
    "        i+=1\n",
    "    return result\n",
    "\n",
    "def projection(datax,kernel=\"poly\",sigma=0,miniX=[],datay=[]):\n",
    "    if kernel==\"poly\":\n",
    "        N=datax.shape[0]\n",
    "        new_datax=np.zeros((N,N))\n",
    "        for i in range(len(datax)):\n",
    "            x1=datax[i]\n",
    "            for j in range(len(datax)):\n",
    "                x2=datax[j]\n",
    "                a=1+x1.dot(x2)\n",
    "                new_datax[i][j]=np.power(a,datax.shape[1])\n",
    "        return new_datax\n",
    "class Linear(object):\n",
    "    def __init__(self,loss=hinge,loss_g=hinge_g,max_iter=1000,eps=0.01, kernel=\"poly\",sigma=0,typeUp=\"batch\",bins=0,nbPoints=100,w_type='random'):\n",
    "        \"\"\" :loss: fonction de cout\n",
    "            :loss_g: gradient de la fonction de cout\n",
    "            :max_iter: nombre d'iterations\n",
    "            :eps: pas de gradient\n",
    "            :kernel: noyau du perceptron\n",
    "        \"\"\"\n",
    "        self.max_iter, self.eps = max_iter,eps\n",
    "        self.loss, self.loss_g = loss, loss_g\n",
    "        self.kernel = kernel\n",
    "        self.sigma=sigma\n",
    "        self.bins=bins\n",
    "        self.typeUp=typeUp\n",
    "        self.miniX=[]\n",
    "        self.nbPoints=nbPoints\n",
    "        self.w_type=w_type\n",
    "        \n",
    "    def fit(self,datax,datay,testx=None,testy=None):\n",
    "        \"\"\" :datax: donnees de train\n",
    "            :datay: label de train\n",
    "            :testx: donnees de test\n",
    "            :testy: label de test\n",
    "        \"\"\"\n",
    "        # on transforme datay en vecteur colonne\n",
    "        datay = datay.reshape(-1,1)\n",
    "        N = len(datay)\n",
    "        datax = datax.reshape(N,-1)\n",
    "        D = datax.shape[1]\n",
    "        if(self.w_type=='random'):\n",
    "            self.w = np.random.random((1,D))\n",
    "        if(self.w_type=='mean'):\n",
    "            self.w = np.array([datax.mean(0)])\n",
    "        self.w_init=copy.deepcopy(self.w)\n",
    "        self.w_hist=[]\n",
    "        data_projected=copy.deepcopy(datax)\n",
    "        \n",
    "        if (self.kernel=='poly'):\n",
    "            self.w = np.random.random((1,D+3))\n",
    "            self.w_init=copy.deepcopy(self.w)\n",
    "        if(self.typeUp=='batch'):      \n",
    "            for i in range(self.max_iter):\n",
    "                self.dd=data_projected\n",
    "                self.cc=self.loss_g(data_projected, datay, self.w)\n",
    "                for j in range(len(data_projected)):\n",
    "                    self.w -= self.eps * self.loss_g(data_projected[i], datay, self.w)\n",
    "                    self.w_hist.append(self.w)\n",
    "        elif(self.typeUp=='stochastique'):\n",
    "            for i in range(self.max_iter):\n",
    "                index=random.choice(np.arange(0,data_projected.shape[0],1))\n",
    "                self.w -= self.eps * self.loss_g(data_projected[index], datay[index], self.w)\n",
    "                self.w_hist.append(self.w)\n",
    "        elif(self.typeUp=='minibatch'):  \n",
    "            list_shuffle=np.arange(0,data_projected.shape[0],1)\n",
    "            np.random.shuffle(list_shuffle)\n",
    "            datax_s=[x for _,x in sorted(zip(list_shuffle,data_projected))]\n",
    "            datay_s=[x for _,x in sorted(zip(list_shuffle,datay))]\n",
    "            mini_binsX=chunks(datax_s,1000)\n",
    "            mini_binsY=chunks(datay_s,1000)\n",
    "            for i in range(len(mini_binsX)):\n",
    "                for j in range(self.max_iter):\n",
    "                    self.w -= self.eps * self.loss_g(np.array(mini_binsX[i]), np.array(mini_binsY[i]), self.w)\n",
    "                    self.w_hist.append(self.w)                   \n",
    "\n",
    "    def predict(self,datax):\n",
    "        data_projected=copy.deepcopy(datax)\n",
    "        if len(datax.shape)==1:\n",
    "            datax = datax.reshape(1,-1)\n",
    "        if(self.kernel=='poly'):\n",
    "            data_projected=self.project_data(copy.deepcopy(datax),None)\n",
    "        return np.sign(np.dot(data_projected, self.w.T)).reshape(-1)\n",
    "\n",
    "    def score(self,datax,datay):\n",
    "        return np.where(self.predict(datax).reshape(-1)==datay,1,0).mean()\n",
    "    def project_data(self,datax,datay):\n",
    "        return projection(datax,self.kernel,sigma=self.sigma,miniX=self.miniX,datay=datay)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Introduction : Module scikit-learn </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax_train, datay_train = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460211463550362"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1= Perceptron(tol=0.01, random_state=0)\n",
    "p1.fit(datax_train, datay_train)\n",
    "p1.score(datax_train,datay_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10127991096271564"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2= Linear(hinge,hinge_g,max_iter=1000,eps=0.001,typeUp='minibatch')\n",
    "p2.fit(datax_train,datay_train)\n",
    "p2.score(datax_train,datay_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Linéaire pénalisé - régularisation de Tikhonov</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> SVM etGrid Search </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx,trainy =  gen_arti(nbex=1000,data_type=0,epsilon=1)\n",
    "testx,testy =  gen_arti(nbex=1000,data_type=0,epsilon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Apprentissage multi-classe </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> String Kernel  </h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
