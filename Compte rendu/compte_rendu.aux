\relax 
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\babel@aux{french}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Arbres de d\IeC {\'e}cision, s\IeC {\'e}lection de mod\IeC {\`e}les}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Exp\IeC {\'e}rience pr\IeC {\'e}liminaires sur le mod\IeC {\`e}le}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Sur et sous apprentissage}{1}}
\@writefile{toc}{\contentsline {paragraph}{}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Courbe de l\IeC {\textquoteright }erreur en apprentissage pour diff\IeC {\'e}rentes partitionnements de l'ensemble des donn\IeC {\'e}es}}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Courbe de l\IeC {\textquoteright }erreur en apprentissage en fonction de la profondeur de l'arbre}}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Courbe de l\IeC {\textquoteright }erreur en test en fonction de la profondeur de l'arbre}}{2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces M\IeC {\'e}morisation de l'ensemble d'apprentissage}}{3}}
\@writefile{toc}{\contentsline {paragraph}{}{3}}
\@writefile{toc}{\contentsline {paragraph}{}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Validation crois\IeC {\'e}e}{3}}
\@writefile{toc}{\contentsline {paragraph}{}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Courbe des erreurs moyennes sur N cas}}{3}}
\@writefile{toc}{\contentsline {paragraph}{}{3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Estimation de densit\IeC {\'e}}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{}{4}}
\@writefile{toc}{\contentsline {paragraph}{}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}D\IeC {\'e}finition}{4}}
\@writefile{toc}{\contentsline {paragraph}{}{4}}
\@writefile{toc}{\contentsline {paragraph}{}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Exp\IeC {\'e}rimentations}{4}}
\@writefile{toc}{\contentsline {paragraph}{}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Estimation de densit\IeC {\'e} par la m\IeC {\'e}thode des histogrammes }}{4}}
\@writefile{toc}{\contentsline {paragraph}{}{4}}
\@writefile{toc}{\contentsline {paragraph}{}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Estimation de densit\IeC {\'e} par la m\IeC {\'e}thode \IeC {\`a} noyaux (Parzen et Gauss)}}{5}}
\@writefile{toc}{\contentsline {paragraph}{}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Calcul du param\IeC {\`e}tre optimal h* de Gauss }{5}}
\@writefile{toc}{\contentsline {paragraph}{}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Estimation de densit\IeC {\'e} avec h* par la m\IeC {\'e}thode \IeC {\`a} noyaux (Gauss)}}{5}}
\@writefile{toc}{\contentsline {paragraph}{}{5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Descente de gradient}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Optimisation de fonctions}{6}}
\@writefile{toc}{\contentsline {paragraph}{}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Exp\IeC {\'e}rimentations}{6}}
\@writefile{toc}{\contentsline {paragraph}{}{6}}
\@writefile{toc}{\contentsline {paragraph}{}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Optimisation de la fonction $f(x)= x\qopname  \relax o{cos}(x)$ pour $\epsilon =0.05$ et le nombre d'it\IeC {\'e}ration=50}}{6}}
\@writefile{toc}{\contentsline {paragraph}{}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Optimisation de la fonction $f(x)= x\qopname  \relax o{cos}(x)$ pour $\epsilon =0.05$ et le nombre d'it\IeC {\'e}ration=50}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Optimisation de la fonction $f(x)= x\qopname  \relax o{cos}(x)$ pour $\epsilon =0.8$ et le nombre d'it\IeC {\'e}ration=50}}{7}}
\@writefile{toc}{\contentsline {paragraph}{}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Optimisation de la fonction $f(x)= x\qopname  \relax o{cos}(x)$ pour $\epsilon =0.001$ et le nombre d'it\IeC {\'e}ration=200}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Optimisation de la fonction $f(x)= x\qopname  \relax o{cos}(x)$ pour $\epsilon =0.001$ et le nombre d'it\IeC {\'e}ration=2000}}{8}}
\@writefile{toc}{\contentsline {paragraph}{}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Optimisation de la fonction $f(x)=-\qopname  \relax o{log}{x}+x^2$ pour $\epsilon =0.1$ et le nombre d'it\IeC {\'e}ration=20}}{8}}
\@writefile{toc}{\contentsline {paragraph}{}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Optimisation de la fonction $f(x)=100(x_1-x_2^2)^2+(1-x_1)^2$ pour $\epsilon =0.005$ et le nombre d'it\IeC {\'e}ration=100}}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}R\IeC {\'e}gression logistique}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Les valeurs de poids de l'exp\IeC {\'e}rience 1Vs7 en fonction de $\epsilon $}}{9}}
\@writefile{toc}{\contentsline {paragraph}{}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Bayes Na\IeC {\"\i }f Vs R\IeC {\'e}gression logistique }{9}}
\@writefile{toc}{\contentsline {paragraph}{}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Perceptron}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}D\IeC {\'e}finition}{10}}
\@writefile{toc}{\contentsline {paragraph}{}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Exp\IeC {\'e}rimentations}{10}}
\@writefile{toc}{\contentsline {paragraph}{}{10}}
\@writefile{toc}{\contentsline {paragraph}{}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Perceptron avec diff\IeC {\'e}rentes fonctions de co\IeC {\^u}t avec $\epsilon =0.2$ et le nombre maximum d'it\IeC {\'e}rations=200}}{10}}
\@writefile{toc}{\contentsline {paragraph}{}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Consid\IeC {\'e}ration du biais}{11}}
\@writefile{toc}{\contentsline {paragraph}{}{11}}
\@writefile{toc}{\contentsline {paragraph}{}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces L'impact du biais sur le perceptron avec $\epsilon =0.2$ et le nombre maximum d'it\IeC {\'e}rations=200}}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Batch - MiniBatch - Stochastique}{11}}
\@writefile{toc}{\contentsline {paragraph}{}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces \IeC {\'E}valuation des variantes de l'algorithme du Perceptron en fonction du nombre d'it\IeC {\'e}rations et avec $\epsilon =0.1$}}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Donn\IeC {\'e}es USPS}{11}}
\@writefile{toc}{\contentsline {paragraph}{}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Visualisation de la matrice des poids sans biais avec $\epsilon =0.1$ et le nombre maximum d'it\IeC {\'e}rations=1000}}{12}}
\@writefile{toc}{\contentsline {paragraph}{}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Les courbes d\IeC {\textquoteright }erreurs en apprentissage et en test en fonction du nombre d\IeC {\textquoteright }it\IeC {\'e}rations. avec $\epsilon =0.1$ }}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Projection polynomiale}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Perceptron avec diff\IeC {\'e}rentes projections polynomiales avec $\epsilon =0.2$ et le nombre maximum d'it\IeC {\'e}rations=1000}}{12}}
\@writefile{toc}{\contentsline {paragraph}{}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Projection gaussienne}{13}}
\@writefile{toc}{\contentsline {paragraph}{}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Projection gaussienne en fonction du nombre de points et des variantes du perceptron $\epsilon =0.2$ et le nombre maximum d'it\IeC {\'e}rations=1000}}{13}}
\@writefile{toc}{\contentsline {paragraph}{}{13}}
